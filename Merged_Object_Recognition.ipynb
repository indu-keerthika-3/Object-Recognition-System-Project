{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b600ef32",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow opencv-python matplotlib numpy gdown\n",
    "\n",
    "import os\n",
    "import requests\n",
    "\n",
    "# Create dataset directories\n",
    "categories = [\"cat\", \"dog\"]\n",
    "os.makedirs(\"dataset/cat\", exist_ok=True)\n",
    "os.makedirs(\"dataset/dog\", exist_ok=True)\n",
    "\n",
    "# Image URLs (from Unsplash)\n",
    "image_urls = {\n",
    "    \"cat\": [\n",
    "        \"https://images.unsplash.com/photo-1518791841217-8f162f1e1131\",\n",
    "        \"https://images.unsplash.com/photo-1574158622682-e40e69881006\"\n",
    "    ],\n",
    "    \"dog\": [\n",
    "        \"https://images.unsplash.com/photo-1560807707-8cc77767d783\",\n",
    "        \"https://images.unsplash.com/photo-1560807707-8cc77767d783\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Download images\n",
    "for category, urls in image_urls.items():\n",
    "    for i, url in enumerate(urls):\n",
    "        img_data = requests.get(url).content\n",
    "        with open(f\"dataset/{category}/{category}{i+1}.jpg\", \"wb\") as handler:\n",
    "            handler.write(img_data)\n",
    "\n",
    "print(\"✅ Sample dataset downloaded and saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee25f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Download dataset from Google Drive if available\n",
    "!gdown --folder --id 1B19RWODijlUlXEdvLKxjcmlg-BiJcbWE -O /content/shared_folder\n",
    "print(\"✅ Dataset downloaded from Google Drive!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a84aaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load a pre-trained model (MobileNetV2 for image classification)\n",
    "model = tf.keras.applications.MobileNetV2(weights=\"imagenet\")\n",
    "\n",
    "# Function to preprocess image\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = tf.keras.applications.mobilenet_v2.preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "# Function to predict object in image\n",
    "def predict_object(image_path):\n",
    "    img = preprocess_image(image_path)\n",
    "    predictions = model.predict(img)\n",
    "    decoded_predictions = tf.keras.applications.mobilenet_v2.decode_predictions(predictions, top=3)[0]\n",
    "\n",
    "    for i, (imagenet_id, label, score) in enumerate(decoded_predictions):\n",
    "        print(f\"{i+1}: {label} ({score:.2f})\")\n",
    "\n",
    "    # Display image\n",
    "    img_display = cv2.imread(image_path)\n",
    "    img_display = cv2.cvtColor(img_display, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img_display)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "sample_image = \"dataset/cat/cat1.jpg\"  # Change this based on dataset availability\n",
    "predict_object(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48ff526-bb23-4d50-9bb4-42815dadb9a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e04348-2b9d-4a08-a2e8-99217e443304",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
